#Домашнее задание по теме "Многопроцессное программирование"
"""Цель: понять разницу между линейным и многопроцессным подходом, выполнив операции обоими способами."""
'''Задача "Многопроцессное считывание":
Необходимо считать информацию из нескольких файлов одновременно, используя многопроцессный подход.
Подготовка:
Скачайте архив с файлами для считывания данных и распакуйте его в проект для дальнейшего использования.
Выполнение:
Создайте функцию read_info(name), где name - название файла. Функция должна:
Создавать локальный список all_data.
Открывать файл name для чтения.
Считывать информацию построчно (readline), пока считанная строка не окажется пустой.
Во время считывания добавлять каждую строку в список all_data.
Этих операций достаточно, чтобы рассмотреть преимущество многопроцессного выполнения программы над линейным.

Создайте список названий файлов в соответствии с названиями файлов архива.
Вызовите функцию read_info для каждого файла по очереди (линейно) и измерьте время выполнения и выведите его в консоль.
Вызовите функцию read_info для каждого файла, используя многопроцессный подход: контекстный менеджер with и 
объект Pool. 
Для вызова функции используйте метод map, передав в него функцию read_info и список названий файлов. Измерьте время 
выполнения и выведите его в консоль.
Для избежания некорректного вывода запускайте линейный вызов и многопроцессный по отдельности, предварительно
 закомментировав другой.

Пример результата выполнения программы:
Выполняемый код:
def read_info(name):
...
filenames = [f'./file {number}.txt' for number in range(1, 5)]

# Линейный вызов

# Многопроцессный

Вывод на консоль, 2 запуска (результаты могут отличаться):
0:00:03.046163 (линейный)
0:00:01.092300 (многопроцессный)

Примечания:
Используйте конструкцию if __name__ == '__main__' при многопроссном подходе.
Выводить или возвращать список all_data в функции не нужно. Можете сделать это, но кол-во информации в 
файлах достигает - 10^9 строк.
Дополнительно о классе Pool можете прочитать здесь.'''
######################################################################################################################
import time  # Для измерения времени выполнения
from multiprocessing import Pool  # Для реализации многопроцессного подхода

# Функция для чтения информации из файла
def read_info(name):
    """
    Считывает содержимое файла построчно и добавляет каждую строку в локальный список.
    Аргументы:
        name (str): Имя файла, который нужно прочитать.
    """
    all_data = []  # Локальный список для хранения данных
    with open(name, 'r', encoding='utf-8') as file:  # Открываем файл для чтения
        while True:
            line = file.readline()  # Считываем строку
            if not line:  # Если строка пустая, заканчиваем чтение
                break
            all_data.append(line)  # Добавляем строку в список (опционально)
    # Мы не возвращаем список all_data, так как он нужен лишь для демонстрации
    # Вместо этого просто выполняем чтение файла.

if __name__ == '__main__':
    # Список названий файлов (здесь предполагается, что файлы имеют названия file1.txt, file2.txt и т.д.)
    filenames = [f'file {number}.txt' for number in range(1, 5)]  # Замените на реальные названия файлов

    # Линейный вызов
    print("Линейный вызов:")
    start_time = time.perf_counter()  # Засекаем начальное время
    for filename in filenames:
        read_info(filename)  # Последовательно вызываем функцию для каждого файла
    end_time = time.perf_counter()  # Засекаем конечное время
    print(f"Время выполнения (линейно): {end_time - start_time:.6f} секунд")

    # Многопроцессный вызов
    print("\nМногопроцессный вызов:")
    start_time = time.perf_counter()  # Засекаем начальное время
    with Pool() as pool:  # Создаем пул процессов
        pool.map(read_info, filenames)  # Параллельно вызываем функцию для каждого файла
    end_time = time.perf_counter()  # Засекаем конечное время
    print(f"Время выполнения (многопроцессно): {end_time - start_time:.6f} секунд")


'''Конструкция `with Pool() as pool` используется для работы с пулом процессов в Python, что позволяет выполнять задачи параллельно на нескольких процессах. Рассмотрим её подробно:  

### **1. Что такое пул процессов (`Pool`)**
`Pool` — это класс из модуля `multiprocessing`, который управляет пулом рабочих процессов. Он автоматически распределяет задачи между доступными процессорами, чтобы ускорить выполнение.

### **2. Почему используется `with`**
Использование контекстного менеджера `with` для создания пула имеет два преимущества:
- **Автоматическое управление ресурсами:** Пул создается в начале блока и автоматически закрывается по его завершении. 
Это освобождает ресурсы и предотвращает утечки памяти.
- **Безопасность:** Не нужно вручную закрывать (`pool.close()`) и ждать завершения (`pool.join()`) всех процессов.
 Это делает код более чистым и надежным.

Пример:
```python
with Pool() as pool:
    # Здесь создается пул процессов
    pool.map(read_info, filenames)
# После завершения работы блока пул автоматически закрывается
```

### **3. Что делает `pool.map`**
Метод `map` распределяет задачи между процессами пула:
- **Аргументы:**
  - Функция (`read_info`): Это функция, которую нужно выполнить.
  - Итерация (`filenames`): Список входных данных, по одному элементу для каждого вызова функции.
- **Как работает:**
  - Каждый процесс из пула получает один элемент из списка `filenames` и вызывает `read_info` с этим элементом.
  - Когда процесс завершает выполнение, он берёт следующий элемент из списка.
  - Это продолжается до тех пор, пока все элементы из списка не будут обработаны.

### **4. В чём преимущество**
- Все файлы обрабатываются одновременно на разных процессах.
- Это существенно сокращает время выполнения по сравнению с последовательным запуском функции.

### **Пример выполнения**

filenames = ['file1.txt', 'file2.txt', 'file3.txt', 'file4.txt']

# Параллельное выполнение
with Pool() as pool:
    pool.map(read_info, filenames)

- Если у вас, например, 4 ядра на процессоре и 4 файла:
  - Каждый файл будет обрабатываться отдельным процессом.
  - В результате все файлы могут быть обработаны практически одновременно.

### **Важные моменты:**
1. **Функция `read_info` должна быть глобально доступной:** Она должна быть определена на уровне модуля, 
иначе процессы не смогут её найти.
2. **Порядок вызовов соблюдается:** Несмотря на параллельное выполнение, метод `map` возвращает результаты в том 
же порядке, что и исходный список.
3. **Производительность зависит от задач:**
   - Если задачи процессорозависимые (много вычислений), выгода от многопроцессности будет значительной.
   - Если задачи ввод/вывод-зависимые (например, чтение файлов), выгода может быть меньше из-за ограничений диска.

### **Резюме**
- `with Pool() as pool` удобно и безопасно управляет пулом процессов.
- `pool.map` автоматически распределяет задачи из списка на несколько процессов.
- Это мощный инструмент для ускорения выполнения задач, особенно в многозадачных сценариях.'''

